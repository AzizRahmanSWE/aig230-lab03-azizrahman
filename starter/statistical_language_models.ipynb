{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91489c36",
   "metadata": {},
   "source": [
    "# AIG230 NLP (Week 3 Lab) — Notebook 2: Statistical Language Models (Train, Test, Evaluate)\n",
    "\n",
    "This notebook focuses on **n-gram Statistical Language Models (SLMs)**:\n",
    "- Train **unigram**, **bigram**, **trigram** models\n",
    "- Handle **OOV** with `<UNK>`\n",
    "- Apply **smoothing** (Add-k)\n",
    "- Evaluate with **cross-entropy** and **perplexity**\n",
    "- Do **next-word prediction** and simple **text generation**\n",
    "\n",
    "> Industry framing: even if modern systems use neural LMs, n-gram LMs are still useful for\n",
    "baselines, constrained domains, and for understanding evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad94cb39",
   "metadata": {},
   "source": [
    "### What is smoothing?\n",
    "\n",
    "Smoothing is a way to stop a language model from saying “this can never happen.”\n",
    "\n",
    "When we train a language model from data, it only knows what it has seen before.\n",
    "If it never saw a particular word sequence, the model would normally give it a probability of zero.\n",
    "\n",
    "Smoothing fixes that.\n",
    "### Why is this a problem without smoothing?\n",
    "\n",
    "Imagine the model learned English only by reading a small number of news articles.\n",
    "\n",
    "If it never saw:\n",
    "\n",
    "- “oil prices explode”\n",
    "\n",
    "the model would conclude:\n",
    "\n",
    "- “That sentence is impossible.”\n",
    "\n",
    "But as humans, we know it could happen. The model just hasn’t seen it yet.\n",
    "\n",
    "Without smoothing:\n",
    "\n",
    "- One unseen word makes the whole sentence probability zero\n",
    "\n",
    "- Evaluation breaks\n",
    "\n",
    "- The model is too confident and too brittle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a046e",
   "metadata": {},
   "source": [
    "## 0) Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ee526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple, Dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc428b4",
   "metadata": {},
   "source": [
    "## 1) Data: domain text you might see in real systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d207e4c",
   "metadata": {},
   "source": [
    "We use short texts that resemble:\n",
    "- release notes\n",
    "- incident summaries\n",
    "- operational runbooks\n",
    "- customer support messaging\n",
    "\n",
    "In practice, you would load thousands to millions of lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb34582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " 4,\n",
       " ['printer driver install fails with error 1603',\n",
       "  'push notifications not working on android app'],\n",
       " ['email delivery delayed messages queued',\n",
       "  'vpn disconnects frequently after windows update'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "corpus = [\n",
    "    \"vpn disconnects frequently after windows update\",\n",
    "    \"password reset link expired user cannot login\",\n",
    "    \"api requests timeout when latency spikes\",\n",
    "    \"portal returns 500 error after deployment\",\n",
    "    \"email delivery delayed messages queued\",\n",
    "    \"mfa prompt never arrives user stuck at login\",\n",
    "    \"wifi drops in meeting rooms access point reboot helps\",\n",
    "    \"outlook search not returning results index corrupted\",\n",
    "    \"printer driver install fails with error 1603\",\n",
    "    \"teams calls choppy audio jitter high\",\n",
    "    \"permission denied accessing shared drive though in correct group\",\n",
    "    \"battery drains fast after bios update power settings unchanged\",\n",
    "    \"push notifications not working on android app\",\n",
    "    \"mailbox full cannot receive emails auto archive not running\",\n",
    "]\n",
    "\n",
    "# Train/test split at sentence level\n",
    "random.seed(42)\n",
    "random.shuffle(corpus)\n",
    "split = int(0.75 * len(corpus))\n",
    "train_texts = corpus[:split]\n",
    "test_texts = corpus[split:]\n",
    "\n",
    "len(train_texts), len(test_texts), train_texts[:2], test_texts[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f9947",
   "metadata": {},
   "source": [
    "## 2) Tokenization + special tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c285f1d",
   "metadata": {},
   "source": [
    "We will:\n",
    "- lowercase\n",
    "- keep alphanumerics\n",
    "- split on whitespace\n",
    "- add sentence boundary tokens: `<s>` and `</s>`\n",
    "\n",
    "We will also map rare tokens to `<UNK>` based on training frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058f87da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<s>',\n",
       " 'printer',\n",
       " 'driver',\n",
       " 'install',\n",
       " 'fails',\n",
       " 'with',\n",
       " 'error',\n",
       " '1603',\n",
       " '</s>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.split()\n",
    "\n",
    "def add_boundaries(tokens: List[str], n: int) -> List[str]:\n",
    "    # For n-grams, prepend (n-1) start tokens for simpler context handling\n",
    "    return [\"<s>\"]*(n-1) + tokens + [\"</s>\"]\n",
    "\n",
    "# Example\n",
    "tokens = tokenize(\"Printer driver install fails with error 1603\")\n",
    "add_boundaries(tokens, n=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25308557",
   "metadata": {},
   "source": [
    "## 3) Build vocabulary and handle OOV with <UNK>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3338f0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['email', 'delivery', 'delayed', 'messages', 'queued'],\n",
       " ['<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Build vocab from training data\n",
    "train_tokens_flat = []\n",
    "for t in train_texts:\n",
    "    train_tokens_flat.extend(tokenize(t))\n",
    "\n",
    "freq = Counter(train_tokens_flat)\n",
    "\n",
    "# Typical practical rule: map tokens with frequency <= 1 to <UNK> in small corpora\n",
    "min_count = 2\n",
    "vocab = {w for w, c in freq.items() if c >= min_count}\n",
    "vocab |= {\"<UNK>\", \"<s>\", \"</s>\"}\n",
    "\n",
    "def replace_oov(tokens: List[str], vocab: set) -> List[str]:\n",
    "    return [tok if tok in vocab else \"<UNK>\" for tok in tokens]\n",
    "\n",
    "# Show OOV effect\n",
    "sample = tokenize(test_texts[0])\n",
    "sample, replace_oov(sample, vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759444a0",
   "metadata": {},
   "source": [
    "## 4) Train n-gram counts (unigram, bigram, trigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eac8fa",
   "metadata": {},
   "source": [
    "We will compute:\n",
    "- `ngram_counts[(w1,...,wn)]`\n",
    "- `context_counts[(w1,...,w_{n-1})]`\n",
    "\n",
    "Then probability:\n",
    "\\ndefault:  P(w_n | context) = count(context + w_n) / count(context)\n",
    "\n",
    "This fails when an n-gram is unseen, so we add smoothing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33672bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(tokens: List[str], n:int) -> List[Tuple[str, ...]]:\n",
    "  return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "def train_ngram_counts(texts: List[str], n:int) -> Dict[Tuple[str, ...], int]:\n",
    "  ngrams_counts = Counter()\n",
    "  context_counts = Counter()\n",
    "  for text in texts:\n",
    "    toks = replace_oov(tokenize(text), vocab)\n",
    "    toks = add_boundaries(toks, n)\n",
    "    for ng in get_ngrams(toks, n):\n",
    "      ngrams_counts[ng] += 1\n",
    "      context = ng[:-1]\n",
    "      context_counts[context] += 1\n",
    "  return ngrams_counts, context_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3684a433",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_ngram_counts() got an unexpected keyword argument 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m unigram_counts, unigram_context \u001b[38;5;241m=\u001b[39m train_ngram_counts(train_texts, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, vocab\u001b[38;5;241m=\u001b[39mvocab )\n\u001b[1;32m      2\u001b[0m unigram_counts\n",
      "\u001b[0;31mTypeError\u001b[0m: train_ngram_counts() got an unexpected keyword argument 'vocab'"
     ]
    }
   ],
   "source": [
    "unigram_counts, unigram_context = train_ngram_counts(train_texts, n=1, vocab=vocab )\n",
    "unigram_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ba7c8",
   "metadata": {},
   "source": [
    "## 5) Add-k smoothing and probability function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed806986",
   "metadata": {},
   "source": [
    "### What does Add-k smoothing do?\n",
    "Add-k smoothing tells the model:\n",
    "\n",
    "- “Even if you didn’t see something, assume it could still happen a little bit.”\n",
    "\n",
    "It does this by:\n",
    "\n",
    "- Giving every possible next word a tiny amount of probability\n",
    "\n",
    "- Not just the ones seen in training\n",
    "\n",
    "So instead of:\n",
    "\n",
    "- seen → possible\n",
    "\n",
    "- unseen → impossible\n",
    "\n",
    "We get:\n",
    "\n",
    "- seen → more likely\n",
    "\n",
    "- unseen → less likely, but still possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea279f3",
   "metadata": {},
   "source": [
    "### Why is it called Add-k?\n",
    "\n",
    "Because we add a small number k to every word count.\n",
    "\n",
    "Think of it as:\n",
    "\n",
    "- adding a tiny “imaginary observation” for every word\n",
    "\n",
    "- so no word ever has zero probability\n",
    "\n",
    "When k is small (like 0.1 or 0.5), it gently smooths the probabilities instead of overpowering real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de565994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the probability of a word appearing next, given the previous words, while making sure the probability is never zero.\n",
    "def prob_addk(ngram: Tuple[str, ...], ngram_counts: Counter, context_counts: Counter, V:int, k: float = 0.5) -> float:\n",
    "  \"\"\"\n",
    "  Computer add-k P(w_n | w_1 ... w_{n-1})\n",
    "  where ngram = (w_1 ... w_{n-1})\n",
    "  \"\"\"\n",
    "  context = ngram[:-1]\n",
    "  # formula for add-k explained in the slides\n",
    "  return  (ngram_counts[ngram] + k) / (context_counts[context] + k * V)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa60ca99",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bigram_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m V = \u001b[38;5;28mlen\u001b[39m(vocab)\n\u001b[32m      2\u001b[39m example = (\u001b[33m\"\u001b[39m\u001b[33m<s>\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mI\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlove\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAI\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m prob_addk(example, \u001b[43mbigram_counts\u001b[49m, bigram_context, V, k=\u001b[32m0.5\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'bigram_counts' is not defined"
     ]
    }
   ],
   "source": [
    "V = len(vocab)\n",
    "example = (\"<s>\", \"I\", \"love\", \"AI\")\n",
    "prob_addk(example, bigram_counts, bigram_context, V, k=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6deec",
   "metadata": {},
   "source": [
    "## 6) Evaluate: cross-entropy and perplexity on test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8426d9",
   "metadata": {},
   "source": [
    "We evaluate an LM by how well it predicts held-out text.\n",
    "\n",
    "Cross-entropy (average negative log probability):\n",
    "H = - (1/N) * sum log2 P(w_i | context)\n",
    "\n",
    "Perplexity:\n",
    "PP = 2^H\n",
    "\n",
    "Lower perplexity is better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d03099",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bigram_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Test it\u001b[39;00m\n\u001b[1;32m     26\u001b[0m V \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(vocab)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBigram Perplexity:\u001b[39m\u001b[38;5;124m\"\u001b[39m, evaluate_perplexity(test_texts, \u001b[38;5;241m2\u001b[39m, bigram_counts, bigram_context, vocab))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bigram_counts' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate_perplexity(texts: List[str], n: int, ngram_counts: Counter, \n",
    "                        context_counts: Counter, vocab: set, k: float = 0.5) -> float:\n",
    "    \"\"\"\n",
    "    Calculate perplexity on test texts.\n",
    "    Lower perplexity = model is less \"surprised\" = better predictions.\n",
    "    \"\"\"\n",
    "    V = len(vocab)\n",
    "    total_log_prob = 0.0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for text in texts:\n",
    "        toks = replace_oov(tokenize(text), vocab)\n",
    "        toks = add_boundaries(toks, n)\n",
    "        \n",
    "        for ng in get_ngrams(toks, n):\n",
    "            prob = prob_addk(ng, ngram_counts, context_counts, V, k)\n",
    "            total_log_prob += math.log2(prob)\n",
    "            total_tokens += 1\n",
    "    \n",
    "    # Cross-entropy H = negative average log probability\n",
    "    H = -total_log_prob / total_tokens\n",
    "    # Perplexity = 2^H\n",
    "    return 2 ** H\n",
    "\n",
    "# Test it\n",
    "V = len(vocab)\n",
    "print(\"Bigram Perplexity:\", evaluate_perplexity(test_texts, 2, bigram_counts, bigram_context, vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef338ce",
   "metadata": {},
   "source": [
    "## 7) Next-word prediction (top-k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d202f5",
   "metadata": {},
   "source": [
    "Given a context, compute the probability of each candidate next token and return the top-k.\n",
    "\n",
    "This mirrors:\n",
    "- autocomplete in constrained domains\n",
    "- template suggestion systems\n",
    "- command prediction in runbooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11363d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top predictions for 'vpn':\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bigram_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Test it\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop predictions for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvpn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word, prob \u001b[38;5;129;01min\u001b[39;00m predict_next_word(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvpn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m, bigram_counts, bigram_context, vocab):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprob\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bigram_counts' is not defined"
     ]
    }
   ],
   "source": [
    "def predict_next_word(context: str, n: int, ngram_counts: Counter, \n",
    "                      context_counts: Counter, vocab: set, top_k: int = 5, k: float = 0.5):\n",
    "    \"\"\"Given a context string, predict the top-k most likely next words.\"\"\"\n",
    "    V = len(vocab)\n",
    "    \n",
    "    # Tokenize and prepare context\n",
    "    context_toks = replace_oov(tokenize(context), vocab)\n",
    "    \n",
    "    # Get last (n-1) tokens for context\n",
    "    if n > 1 and len(context_toks) >= n-1:\n",
    "        ctx = tuple(context_toks[-(n-1):])\n",
    "    elif n > 1:\n",
    "        ctx = tuple([\"<s>\"] * (n-1 - len(context_toks)) + context_toks)\n",
    "    else:\n",
    "        ctx = tuple()\n",
    "    \n",
    "    # Score each possible next word\n",
    "    predictions = []\n",
    "    for word in vocab:\n",
    "        if word in [\"<s>\", \"</s>\", \"<UNK>\"]:\n",
    "            continue\n",
    "        ng = ctx + (word,)\n",
    "        prob = prob_addk(ng, ngram_counts, context_counts, V, k)\n",
    "        predictions.append((word, prob))\n",
    "    \n",
    "    # Sort by probability, return top-k\n",
    "    predictions.sort(key=lambda x: -x[1])\n",
    "    return predictions[:top_k]\n",
    "\n",
    "# Test it\n",
    "print(\"Top predictions for 'vpn':\")\n",
    "for word, prob in predict_next_word(\"vpn\", 2, bigram_counts, bigram_context, vocab):\n",
    "    print(f\"  {word}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672e1e9",
   "metadata": {},
   "source": [
    "## 8) Simple generation (bigram or trigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd41fb",
   "metadata": {},
   "source": [
    "Text generation is not the main goal in SLMs, but it helps you verify:\n",
    "- boundary handling\n",
    "- smoothing\n",
    "- OOV decisions\n",
    "\n",
    "We will sample tokens until we hit `</s>`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8d1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_next(context_tokens: List[str], n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, k_smooth: float = 0.5):\n",
    "    V = len(vocab)\n",
    "    context = tuple(context_tokens[-(n-1):]) if n > 1 else tuple()\n",
    "    words = [w for w in vocab if w != \"<s>\"]\n",
    "    probs = []\n",
    "    for w in words:\n",
    "        ng = context + (w,)\n",
    "        probs.append(prob_addk(ng, ngram_counts, context_counts, V, k=k_smooth))\n",
    "    # Normalize\n",
    "    s = sum(probs)\n",
    "    probs = [p/s for p in probs]\n",
    "    return random.choices(words, weights=probs, k=1)[0]\n",
    "\n",
    "def generate(n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, max_len: int = 20, k_smooth: float = 0.5):\n",
    "    tokens = [\"<s>\"]*(n-1) if n > 1 else []\n",
    "    out = []\n",
    "    for _ in range(max_len):\n",
    "        w = sample_next(tokens, n, ngram_counts, context_counts, vocab, k_smooth=k_smooth)\n",
    "        if w == \"</s>\":\n",
    "            break\n",
    "        out.append(w)\n",
    "        tokens.append(w)\n",
    "    return \" \".join(out)\n",
    "\n",
    "for _ in range(5):\n",
    "    print(\"BIGRAM:\", generate(2, bi_counts, bi_ctx, vocab, max_len=18))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db5405",
   "metadata": {},
   "source": [
    "## 9) Model comparison: effect of n and smoothing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7486afd",
   "metadata": {},
   "source": [
    "Try different `k` values. Notes:\n",
    "- `k=1.0` is Laplace smoothing (often too strong)\n",
    "- smaller `k` (like 0.1 to 0.5) is often better\n",
    "\n",
    "In real corpora, trigrams often beat bigrams, but require more data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb25609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect of smoothing parameter k on perplexity:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bigram_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k_val \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m]:\n\u001b[0;32m----> 5\u001b[0m     ppl \u001b[38;5;241m=\u001b[39m evaluate_perplexity(test_texts, \u001b[38;5;241m2\u001b[39m, bigram_counts, bigram_context, vocab, k\u001b[38;5;241m=\u001b[39mk_val)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Perplexity = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mppl\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCompare n-gram orders:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bigram_counts' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare different smoothing values\n",
    "print(\"Effect of smoothing parameter k on perplexity:\")\n",
    "print(\"-\" * 40)\n",
    "for k_val in [0.1, 0.5, 1.0, 2.0]:\n",
    "    ppl = evaluate_perplexity(test_texts, 2, bigram_counts, bigram_context, vocab, k=k_val)\n",
    "    print(f\"k = {k_val}: Perplexity = {ppl:.2f}\")\n",
    "\n",
    "print(\"\\nCompare n-gram orders:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Unigram: {evaluate_perplexity(test_texts, 1, unigram_counts, unigram_context, vocab):.2f}\")\n",
    "print(f\"Bigram:  {evaluate_perplexity(test_texts, 2, bigram_counts, bigram_context, vocab):.2f}\")\n",
    "print(f\"Trigram: {evaluate_perplexity(test_texts, 3, trigram_counts, trigram_context, vocab):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be49abe",
   "metadata": {},
   "source": [
    "## Exercises (do these during lab)\n",
    "1) Add 20 more realistic domain sentences to the corpus and re-run training/evaluation.  \n",
    "2) Change `min_count` (OOV threshold) and explain how perplexity changes.  \n",
    "3) Implement **backoff**: if a trigram is unseen, fall back to bigram; if unseen, fall back to unigram.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5c844",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
